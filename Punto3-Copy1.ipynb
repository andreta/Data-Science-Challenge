{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensimNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading gensim-4.3.2-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.10.1-cp38-cp38-win_amd64.whl (42.2 MB)\n",
      "Installing collected packages: smart-open, scipy, gensim\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.6.2\n",
      "    Uninstalling scipy-1.6.2:\n",
      "      Successfully uninstalled scipy-1.6.2\n",
      "Successfully installed gensim-4.3.2 scipy-1.10.1 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd , numpy as np, seaborn as sb, seaborn as sns,warnings, os, matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from itertools import combinations\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'items_titles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-dec1d02c5b0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'items_titles.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'items_titles_test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'items_titles.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('items_titles.csv')\n",
    "df_test = pd.read_csv('items_titles_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud entre 'zapatillas nike' y 'Zapatos nike' es: 0.6216099262237549\n",
      "La similitud entre 'zapatillas nike' y 'zapatillas nikke' es: 0.4947076439857483\n",
      "La similitud entre 'zapatillas nike' y 'zapatillas nike grandes' es: 0.8369499444961548\n",
      "La similitud entre 'zapatillas nike' y 'zapatillas' es: 0.7138404846191406\n",
      "La similitud entre 'zapatillas nike' y 'tenis' es: -0.12841075658798218\n",
      "La similitud entre 'zapatillas nike' y 'tenis geo talla 2' es: -0.021894939243793488\n",
      "La similitud entre 'zapatillas nike' y 'Zapatos' es: 0.1273036003112793\n",
      "La similitud entre 'zapatillas nike' y 'Ropa de bebe' es: -0.03839060664176941\n",
      "La similitud entre 'zapatillas nike' y 'Zapatos Jordan' es: 0.019483188167214394\n",
      "La similitud entre 'Zapatos nike' y 'zapatillas nikke' es: 0.13116997480392456\n",
      "La similitud entre 'Zapatos nike' y 'zapatillas nike grandes' es: 0.4985864758491516\n",
      "La similitud entre 'Zapatos nike' y 'zapatillas' es: 0.21758940815925598\n",
      "La similitud entre 'Zapatos nike' y 'tenis' es: -0.07837802171707153\n",
      "La similitud entre 'Zapatos nike' y 'tenis geo talla 2' es: -0.09317818284034729\n",
      "La similitud entre 'Zapatos nike' y 'Zapatos' es: 0.6881730556488037\n",
      "La similitud entre 'Zapatos nike' y 'Ropa de bebe' es: -0.04003845900297165\n",
      "La similitud entre 'Zapatos nike' y 'Zapatos Jordan' es: 0.4566000998020172\n",
      "La similitud entre 'zapatillas nikke' y 'zapatillas nike grandes' es: 0.37809404730796814\n",
      "La similitud entre 'zapatillas nikke' y 'zapatillas' es: 0.678272008895874\n",
      "La similitud entre 'zapatillas nikke' y 'tenis' es: -0.03401534631848335\n",
      "La similitud entre 'zapatillas nikke' y 'tenis geo talla 2' es: 0.0434287004172802\n",
      "La similitud entre 'zapatillas nikke' y 'Zapatos' es: 0.1390400230884552\n",
      "La similitud entre 'zapatillas nikke' y 'Ropa de bebe' es: 0.05486540496349335\n",
      "La similitud entre 'zapatillas nikke' y 'Zapatos Jordan' es: -0.023008370772004128\n",
      "La similitud entre 'zapatillas nike grandes' y 'zapatillas' es: 0.5510899424552917\n",
      "La similitud entre 'zapatillas nike grandes' y 'tenis' es: -0.0534394234418869\n",
      "La similitud entre 'zapatillas nike grandes' y 'tenis geo talla 2' es: 0.01334077026695013\n",
      "La similitud entre 'zapatillas nike grandes' y 'Zapatos' es: 0.032581642270088196\n",
      "La similitud entre 'zapatillas nike grandes' y 'Ropa de bebe' es: -0.022653402760624886\n",
      "La similitud entre 'zapatillas nike grandes' y 'Zapatos Jordan' es: -0.08047322928905487\n",
      "La similitud entre 'zapatillas' y 'tenis' es: -0.027131110429763794\n",
      "La similitud entre 'zapatillas' y 'tenis geo talla 2' es: 0.15581560134887695\n",
      "La similitud entre 'zapatillas' y 'Zapatos' es: 0.259353369474411\n",
      "La similitud entre 'zapatillas' y 'Ropa de bebe' es: 0.0030283837113529444\n",
      "La similitud entre 'zapatillas' y 'Zapatos Jordan' es: 0.04936782270669937\n",
      "La similitud entre 'tenis' y 'tenis geo talla 2' es: 0.5867364406585693\n",
      "La similitud entre 'tenis' y 'Zapatos' es: 0.04788962006568909\n",
      "La similitud entre 'tenis' y 'Ropa de bebe' es: -0.04021873697638512\n",
      "La similitud entre 'tenis' y 'Zapatos Jordan' es: -0.011473148129880428\n",
      "La similitud entre 'tenis geo talla 2' y 'Zapatos' es: 0.05541684105992317\n",
      "La similitud entre 'tenis geo talla 2' y 'Ropa de bebe' es: -0.16241507232189178\n",
      "La similitud entre 'tenis geo talla 2' y 'Zapatos Jordan' es: -0.07472766935825348\n",
      "La similitud entre 'Zapatos' y 'Ropa de bebe' es: 0.0026800150517374277\n",
      "La similitud entre 'Zapatos' y 'Zapatos Jordan' es: 0.6360140442848206\n",
      "La similitud entre 'Ropa de bebe' y 'Zapatos Jordan' es: -0.0690205842256546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "titulos = [\"zapatillas nike\",\"Zapatos nike\", \"zapatillas nikke\", \"zapatillas nike grandes\", \"zapatillas\", \"tenis\",\"tenis geo talla 2\",\"Zapatos\",'Ropa de bebe','Zapatos Jordan']\n",
    "\n",
    "tokenized_titles = [word_tokenize(titulo.lower()) for titulo in titulos]\n",
    "\n",
    "model = Word2Vec(tokenized_titles, vector_size=114, window=5, min_count=1, workers=6,epochs=175)\n",
    "\n",
    "for titulo1, titulo2 in combinations(titulos, 2):\n",
    "    palabras1 = word_tokenize(titulo1.lower())\n",
    "    palabras2 = word_tokenize(titulo2.lower())\n",
    "\n",
    "    similarity = model.wv.n_similarity(palabras1, palabras2)\n",
    "    print(f\"La similitud entre '{titulo1}' y '{titulo2}' es: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La similitud entre 'zapatillas nike' y 'zapatillas nikke' es: 0.7846263647079468\n",
      "La similitud entre 'zapatillas nike' y 'ropa deportiva nike' es: 0.6225166320800781\n",
      "La similitud entre 'zapatillas nike' y 'accesorios adidas' es: 0.595533013343811\n",
      "La similitud entre 'zapatillas nike' y 'zapatillas nike grandes' es: 0.7978516221046448\n",
      "La similitud entre 'zapatillas nike' y 'zapatillas aquiles' es: 0.6896889209747314\n",
      "La similitud entre 'zapatillas nike' y 'tenis geo' es: 0.4600256085395813\n",
      "La similitud entre 'zapatillas nike' y 'tenis geo talla 2' es: 0.45129600167274475\n",
      "La similitud entre 'zapatillas nike' y 'ropa azil' es: 0.5586099028587341\n",
      "La similitud entre 'zapatillas nikke' y 'ropa deportiva nike' es: 0.580716073513031\n",
      "La similitud entre 'zapatillas nikke' y 'accesorios adidas' es: 0.5868659019470215\n",
      "La similitud entre 'zapatillas nikke' y 'zapatillas nike grandes' es: 0.7442139387130737\n",
      "La similitud entre 'zapatillas nikke' y 'zapatillas aquiles' es: 0.5853251814842224\n",
      "La similitud entre 'zapatillas nikke' y 'tenis geo' es: 0.3855234980583191\n",
      "La similitud entre 'zapatillas nikke' y 'tenis geo talla 2' es: 0.5231274366378784\n",
      "La similitud entre 'zapatillas nikke' y 'ropa azil' es: 0.6266155242919922\n",
      "La similitud entre 'ropa deportiva nike' y 'accesorios adidas' es: 0.7413223385810852\n",
      "La similitud entre 'ropa deportiva nike' y 'zapatillas nike grandes' es: 0.7429184913635254\n",
      "La similitud entre 'ropa deportiva nike' y 'zapatillas aquiles' es: 0.5997031927108765\n",
      "La similitud entre 'ropa deportiva nike' y 'tenis geo' es: 0.48610687255859375\n",
      "La similitud entre 'ropa deportiva nike' y 'tenis geo talla 2' es: 0.5231326818466187\n",
      "La similitud entre 'ropa deportiva nike' y 'ropa azil' es: 0.6328485012054443\n",
      "La similitud entre 'accesorios adidas' y 'zapatillas nike grandes' es: 0.7302933931350708\n",
      "La similitud entre 'accesorios adidas' y 'zapatillas aquiles' es: 0.568106472492218\n",
      "La similitud entre 'accesorios adidas' y 'tenis geo' es: 0.49952366948127747\n",
      "La similitud entre 'accesorios adidas' y 'tenis geo talla 2' es: 0.5963859558105469\n",
      "La similitud entre 'accesorios adidas' y 'ropa azil' es: 0.6115546822547913\n",
      "La similitud entre 'zapatillas nike grandes' y 'zapatillas aquiles' es: 0.7781974673271179\n",
      "La similitud entre 'zapatillas nike grandes' y 'tenis geo' es: 0.4445909261703491\n",
      "La similitud entre 'zapatillas nike grandes' y 'tenis geo talla 2' es: 0.5123544335365295\n",
      "La similitud entre 'zapatillas nike grandes' y 'ropa azil' es: 0.5866149067878723\n",
      "La similitud entre 'zapatillas aquiles' y 'tenis geo' es: 0.34001827239990234\n",
      "La similitud entre 'zapatillas aquiles' y 'tenis geo talla 2' es: 0.31741800904273987\n",
      "La similitud entre 'zapatillas aquiles' y 'ropa azil' es: 0.3936759829521179\n",
      "La similitud entre 'tenis geo' y 'tenis geo talla 2' es: 0.7838180661201477\n",
      "La similitud entre 'tenis geo' y 'ropa azil' es: 0.5474158525466919\n",
      "La similitud entre 'tenis geo talla 2' y 'ropa azil' es: 0.6828573346138\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "titulos = [\"zapatillas nike\", \"zapatillas nikke\", \"ropa deportiva nike\", \"accesorios adidas\", \"zapatillas nike grandes\", \"zapatillas aquiles\", \"tenis geo\", \"tenis geo talla 2\",\"ropa azil\"]\n",
    "\n",
    "tokenized_titles = [\" \".join(word_tokenize(titulo.lower())) for titulo in titulos]\n",
    "\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "title_embeddings = []\n",
    "for titulo in tokenized_titles:\n",
    "    inputs = tokenizer(titulo, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).detach().numpy()\n",
    "    title_embeddings.append(embeddings)\n",
    "\n",
    "for (titulo1, emb1), (titulo2, emb2) in combinations(zip(titulos, title_embeddings), 2):\n",
    "    similarity = np.dot(emb1.flatten(), emb2.flatten()) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    print(f\"La similitud entre '{titulo1}' y '{titulo2}' es: {similarity}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
